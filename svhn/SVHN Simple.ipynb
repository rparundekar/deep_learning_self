{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "\n",
    "# Imports\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "import matplotlib\n",
    "from pylab import imshow, show, cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from skimage import io\n",
    "import math\n",
    "import random\n",
    "from skimage.transform import resize\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Reshape, AveragePooling2D, MaxPooling2D, Input, Flatten, merge, Convolution2D, Dropout, LocallyConnected2D\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "imgSize = 54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define some useful Functions\n",
    "def get_box_data(index, hdf5_data):\n",
    "    \"\"\"\n",
    "    get `left, top, width, height` of each picture\n",
    "    :param index:\n",
    "    :param hdf5_data:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    meta_data = dict()\n",
    "    meta_data['height'] = []\n",
    "    meta_data['label'] = []\n",
    "    meta_data['left'] = []\n",
    "    meta_data['top'] = []\n",
    "    meta_data['width'] = []\n",
    "\n",
    "    def print_attrs(name, obj):\n",
    "        vals = []\n",
    "        if obj.shape[0] == 1:\n",
    "            vals.append(obj[0][0])\n",
    "        else:\n",
    "            for k in range(obj.shape[0]):\n",
    "                vals.append(int(hdf5_data[obj[k][0]][0][0]))\n",
    "        meta_data[name] = vals\n",
    "\n",
    "    box = hdf5_data['/digitStruct/bbox'][index]\n",
    "    hdf5_data[box[0]].visititems(print_attrs)\n",
    "    return meta_data\n",
    "\n",
    "def get_name(index, hdf5_data):\n",
    "    name = hdf5_data['/digitStruct/name']\n",
    "    return ''.join([chr(v[0]) for v in hdf5_data[name[index][0]].value])\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "def oneHot(num, length):\n",
    "    arr = np.zeros(length)\n",
    "    arr[num-1]=1\n",
    "    return arr\n",
    "\n",
    "def maybeLoadData(folder, force=False, variations=False):\n",
    "    import os.path\n",
    "    import pickle\n",
    "    file_path=folder + 'data.pk'\n",
    "    if(os.path.exists(file_path) is False) or force==True:\n",
    "        imageData, imageLengths, imageDigits = loadData(folder, variations)\n",
    "        data = { 'imageData': imageData, 'imageLengths': imageLengths, 'imageDigits': imageDigits}\n",
    "        pickle.dump(data , open( file_path, \"wb\" ))\n",
    "    \n",
    "    data = pickle.load( open( file_path, \"rb\" ) );\n",
    "    return data['imageData'], data['imageLengths'], data['imageDigits']\n",
    "\n",
    "\n",
    "def loadData(folder, variations=False):\n",
    "    #First load the data using h5py\n",
    "    f = h5py.File(folder + '/' + 'digitStruct.mat')\n",
    "    #Get the number of images to iterate through them\n",
    "    length = len(f['/digitStruct/name'])\n",
    "\n",
    "    #length = 10;   #TestLength\n",
    "\n",
    "    imageData = np.zeros([length, imgSize,imgSize,3]).astype(np.float32)\n",
    "    imageLengths = np.zeros([length, 5]).astype(np.int)\n",
    "    imageDigits = np.zeros([length,5,10]).astype(np.int)\n",
    "\n",
    "    #Iterate through the images\n",
    "    for i in range(0,length):\n",
    "        if(i%500==0): #In case of error, comment this line\n",
    "            print(\"Loaded {} out of {}\".format(i,length))\n",
    "\n",
    "        #Read the image\n",
    "        imageFile = folder + '/' + get_name(i,f)\n",
    "        img = io.imread(imageFile)\n",
    "        #Read the box data & get the bounding box for all characters (using first and last digit)\n",
    "        boxData=get_box_data(i, f)\n",
    "\n",
    "        firstTop = int(boxData['top'][0])\n",
    "        firstLeft = int(boxData['left'][0])\n",
    "        firstRight = int(boxData['left'][0]) + int(boxData['width'][0])\n",
    "        firstBottom = int(boxData['top'][0]) + int(boxData['height'][0])\n",
    "\n",
    "        l = len(boxData['top'])\n",
    "        lastTop = int(boxData['top'][l-1])\n",
    "        lastLeft = int(boxData['left'][l-1])\n",
    "        lastRight = int(boxData['left'][l-1]) + int(boxData['width'][l-1])\n",
    "        lastBottom = int(boxData['top'][l-1]) + int(boxData['height'][l-1])\n",
    "\n",
    "        top = min(firstTop, lastTop)\n",
    "        left = min(firstLeft, lastLeft)\n",
    "        right = max(firstRight, lastRight)\n",
    "        bottom = max(firstBottom, lastBottom)\n",
    "\n",
    "        height = bottom-top\n",
    "        width = right-left\n",
    "        vertMiddle = (bottom+top)//2\n",
    "        horCenter = (left+right)//2\n",
    "\n",
    "        if(variations==True):\n",
    "            top = vertMiddle - ((1.3*height)//2)\n",
    "            bottom = vertMiddle + ((1.3*height)//2)\n",
    "            left = horCenter - ((1.3*width)//2)\n",
    "            right = horCenter + ((1.3*width)//2)\n",
    "\n",
    "        top = int(max(top, 0))\n",
    "        left = int(max(left, 0))\n",
    "        right = int(min(right, img.shape[1]))\n",
    "        bottom = int(min(bottom, img.shape[0]))\n",
    "\n",
    "\n",
    "        #Extract only the RoI for faster pre-processing\n",
    "        img = img[top:bottom, left:right]\n",
    "\n",
    "\n",
    "        #Length of digits\n",
    "        numberOfDigits = len(boxData['label'])\n",
    "\n",
    "        if(variations==True):\n",
    "            #Resize the image to 64x64\n",
    "            img = resize(img,(64, 64))\n",
    "            leftStart=random.randint(0,9)\n",
    "            topStart=random.randint(0,9)\n",
    "            img = img[topStart:(topStart+imgSize), leftStart:(leftStart+imgSize)]\n",
    "        else:\n",
    "            img = resize(img,(imgSize, imgSize))\n",
    "\n",
    "        \n",
    "        #Copy the data\n",
    "        oneImageData = np.resize(img, (imgSize,imgSize,3)).astype(np.float32)\n",
    "        #plt.imshow(oneImageData)\n",
    "        #plt.show()\n",
    "\n",
    "        oneImageData=oneImageData/255.0\n",
    "        imageData[i] = oneImageData\n",
    "        first=0\n",
    "        if(numberOfDigits>5):\n",
    "            numberOfDigits=5\n",
    "            print(boxData['label'])\n",
    "            first=1\n",
    "\n",
    "        imageLengths[i] = oneHot(numberOfDigits,5)\n",
    "\n",
    "        for k in range(0,5):\n",
    "            if(k<numberOfDigits):\n",
    "                imageDigits[i,k,:]=oneHot(int(boxData['label'][int(k+first)]),10)\n",
    "#             else:\n",
    "#                 imageDigits[i,k,10]=1\n",
    "\n",
    "    \n",
    "    shuffledIndexes  = np.arange(length)\n",
    "    np.random.shuffle(shuffledIndexes)\n",
    "\n",
    "    imageData = imageData[shuffledIndexes,:,:,:]\n",
    "    imageLengths = imageLengths[shuffledIndexes,:]\n",
    "    imageDigits = imageDigits[shuffledIndexes,:,:]\n",
    "    return imageData,imageLengths, imageDigits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Training data images: (33402, 54, 54, 3)\n",
      "              length: (33402, 5)\n",
      "              digits: (33402, 5, 10)\n",
      "Loading test & validation data\n",
      "Folder test data images: (13068, 54, 54, 3)\n",
      "          length: (13068, 5)\n",
      "          digits: (13068, 5, 10)\n",
      "Validation data images: (6534, 54, 54, 3)\n",
      "                length: (6534, 5)\n",
      "                digits: (6534, 5, 10)\n",
      "Test data images: (6534, 54, 54, 3)\n",
      "          length: (6534, 5)\n",
      "          digits: (6534, 5, 10)\n",
      "Data loaded.\n"
     ]
    }
   ],
   "source": [
    "trainPath = '/home/carnd/data/svhn/train'\n",
    "testPath = '/home/carnd/data/svhn/test'\n",
    "\n",
    "print(\"Loading data\")\n",
    "trainImageData, trainImageLengths,trainImageDigits = maybeLoadData(trainPath, force=False, variations=False)\n",
    "print(\"Training data images: {}\".format(trainImageData.shape))\n",
    "print(\"              length: {}\".format(trainImageLengths.shape))\n",
    "print(\"              digits: {}\".format(trainImageDigits.shape))\n",
    "\n",
    "print(\"Loading test & validation data\")\n",
    "folderImageData, folderImageLengths,folderImageDigits = maybeLoadData(testPath, force=False, variations=False)\n",
    "print(\"Folder test data images: {}\".format(folderImageData.shape))\n",
    "print(\"          length: {}\".format(folderImageLengths.shape))\n",
    "print(\"          digits: {}\".format(folderImageDigits.shape))\n",
    "\n",
    "half = len(folderImageData)//2\n",
    "validationImageData = folderImageData[0:half,:]\n",
    "validationImageLengths = folderImageLengths[0:half,:]\n",
    "validationImageDigits= folderImageDigits[0:half,:,:]\n",
    "print(\"Validation data images: {}\".format(validationImageData.shape))\n",
    "print(\"                length: {}\".format(validationImageLengths.shape))\n",
    "print(\"                digits: {}\".format(validationImageDigits.shape))\n",
    "\n",
    "testImageData = folderImageData[half:,:]\n",
    "testImageLengths = folderImageLengths[half:,:]\n",
    "testImageDigits= folderImageDigits[half:,:,:]\n",
    "print(\"Test data images: {}\".format(testImageData.shape))\n",
    "print(\"          length: {}\".format(testImageLengths.shape))\n",
    "print(\"          digits: {}\".format(testImageDigits.shape))\n",
    "\n",
    "print(\"Data loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0UHkxE8kOoic+IlEB/H/AQUm2iS874O0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd8f481a2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0]\n",
      "[[0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n",
      "[0 0 1 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 1 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#Confirm Data\n",
    "d=6135\n",
    "plt.imshow(trainImageData[d]*255)\n",
    "plt.show()\n",
    "print(trainImageLengths[d])\n",
    "print(trainImageDigits[d])\n",
    "\n",
    "trainDigit0  = trainImageDigits[:,0,:]\n",
    "trainDigit1  = trainImageDigits[:,1,:]\n",
    "trainDigit2  = trainImageDigits[:,2,:]\n",
    "trainDigit3  = trainImageDigits[:,3,:]\n",
    "trainDigit4  = trainImageDigits[:,4,:]\n",
    "\n",
    "print(trainDigit0[d])\n",
    "print(trainDigit1[d])\n",
    "print(trainDigit2[d])\n",
    "print(trainDigit3[d])\n",
    "print(trainDigit4[d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputSize=imgSize*imgSize\n",
    "channels=3\n",
    "num_labels=5\n",
    "\n",
    "def getCnnModel():\n",
    "    x = Input(batch_shape=(None, imgSize, imgSize,channels))\n",
    "\n",
    "    conv = Convolution2D(64, (5, 5), strides=(1, 1), padding='same', name = \"conv1\", activation='relu')(x)\n",
    "    conv = MaxPooling2D(pool_size = (2,2))(conv)\n",
    "    conv = BatchNormalization()(conv)\n",
    "\n",
    "    conv = Convolution2D(128, (5, 5), strides=(1, 1), padding='same', name = \"conv2\", activation='relu')(conv)\n",
    "    conv = MaxPooling2D(pool_size = (2,2))(conv)\n",
    "    conv = BatchNormalization()(conv)\n",
    "\n",
    "    conv = Convolution2D(256, (5, 5), strides=(1, 1),padding='same', name = \"conv3\", activation='relu')(conv)\n",
    "    conv = MaxPooling2D(pool_size = (2,2))(conv)\n",
    "    conv = BatchNormalization()(conv)\n",
    "\n",
    "    conv = Convolution2D(1024, (5, 5), strides=(1, 1),padding='same', name = \"conv4\", activation='relu')(conv)\n",
    "    conv = MaxPooling2D(pool_size = (2,2))(conv)\n",
    "    conv = BatchNormalization()(conv)\n",
    "\n",
    "\n",
    "    flat = Flatten()(conv)\n",
    "\n",
    "    dense = Dense(1024, activation='relu')(flat)\n",
    "    dense = BatchNormalization()(dense)\n",
    "    dense = Dropout(0.3)(dense)\n",
    "    dense = Dense(1024, activation='relu')(dense)\n",
    "    dense = BatchNormalization()(dense)\n",
    "    dense = Dropout(0.3)(dense)\n",
    "    dense = Dense(1024, activation='relu')(dense)\n",
    "    dense = BatchNormalization()(dense)\n",
    "    dense = Dropout(0.3)(dense)\n",
    "    \n",
    "    outL = Dense(5)(dense)\n",
    "    outL = Activation('softmax', name=\"Length\")(outL)\n",
    "\n",
    "    outD0 = Dense(10)(dense)\n",
    "    outD0 = Activation('sigmoid', name=\"Digit0\")(outD0)\n",
    "    outD1 = Dense(10)(dense)\n",
    "    outD1 = Activation('sigmoid', name=\"Digit1\")(outD1)\n",
    "    outD2 = Dense(10)(dense)\n",
    "    outD2 = Activation('sigmoid', name=\"Digit2\")(outD2)\n",
    "    outD3 = Dense(10)(dense)\n",
    "    outD3 = Activation('sigmoid', name=\"Digit3\")(outD3)\n",
    "    outD4 = Dense(10)(dense)\n",
    "    outD4 = Activation('sigmoid', name=\"Digit4\")(outD4)\n",
    "    model = Model(input=x, output=[outL, outD0, outD1, outD2, outD3, outD4])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/__main__.py:50: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=Tensor(\"in...)`\n",
      "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/__main__.py:28: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 54, 54, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                   (None, 54, 54, 64)    4864        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 27, 27, 64)    0           conv1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 27, 27, 64)    256         max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                   (None, 27, 27, 128)   204928      batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 13, 13, 128)   0           conv2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 13, 13, 128)   512         max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                   (None, 13, 13, 256)   819456      batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, 6, 6, 256)     0           conv3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 6, 6, 256)     1024        max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv4 (Conv2D)                   (None, 6, 6, 1024)    6554624     batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)   (None, 3, 3, 1024)    0           conv4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 3, 3, 1024)    4096        max_pooling2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 9216)          0           batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1024)          9438208     flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 1024)          4096        dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 1024)          0           batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1024)          1049600     dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 1024)          4096        dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 1024)          0           batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 1024)          1049600     dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, 1024)          4096        dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 1024)          0           batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 5)             5125        dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 10)            10250       dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 10)            10250       dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 10)            10250       dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 10)            10250       dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 10)            10250       dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "Length (Activation)              (None, 5)             0           dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "Digit0 (Activation)              (None, 10)            0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "Digit1 (Activation)              (None, 10)            0           dense_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "Digit2 (Activation)              (None, 10)            0           dense_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "Digit3 (Activation)              (None, 10)            0           dense_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "Digit4 (Activation)              (None, 10)            0           dense_9[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 19,195,831\n",
      "Trainable params: 19,186,743\n",
      "Non-trainable params: 9,088\n",
      "____________________________________________________________________________________________________\n",
      "Train on 33402 samples, validate on 6534 samples\n",
      "Epoch 1/25\n",
      "130s - loss: 1.9424 - Length_loss: 0.3998 - Digit0_loss: 0.4238 - Digit1_loss: 0.4168 - Digit2_loss: 0.2876 - Digit3_loss: 0.2156 - Digit4_loss: 0.1988 - Length_acc: 0.8463 - Digit0_acc: 0.8311 - Digit1_acc: 0.8446 - Digit2_acc: 0.8933 - Digit3_acc: 0.9193 - Digit4_acc: 0.9239 - val_loss: 1.0996 - val_Length_loss: 0.4033 - val_Digit0_loss: 0.2954 - val_Digit1_loss: 0.2833 - val_Digit2_loss: 0.0908 - val_Digit3_loss: 0.0173 - val_Digit4_loss: 0.0094 - val_Length_acc: 0.8000 - val_Digit0_acc: 0.9000 - val_Digit1_acc: 0.9190 - val_Digit2_acc: 0.9828 - val_Digit3_acc: 0.9989 - val_Digit4_acc: 1.0000\n",
      "Epoch 2/25\n",
      "119s - loss: 0.8160 - Length_loss: 0.1432 - Digit0_loss: 0.2512 - Digit1_loss: 0.2810 - Digit2_loss: 0.1137 - Digit3_loss: 0.0230 - Digit4_loss: 0.0039 - Length_acc: 0.9436 - Digit0_acc: 0.9145 - Digit1_acc: 0.9151 - Digit2_acc: 0.9694 - Digit3_acc: 0.9956 - Digit4_acc: 0.9999 - val_loss: 1.6744 - val_Length_loss: 0.6719 - val_Digit0_loss: 0.5516 - val_Digit1_loss: 0.3351 - val_Digit2_loss: 0.1063 - val_Digit3_loss: 0.0091 - val_Digit4_loss: 3.5873e-04 - val_Length_acc: 0.8553 - val_Digit0_acc: 0.8564 - val_Digit1_acc: 0.9190 - val_Digit2_acc: 0.9828 - val_Digit3_acc: 0.9989 - val_Digit4_acc: 1.0000\n",
      "Epoch 3/25\n",
      "119s - loss: 0.5443 - Length_loss: 0.0831 - Digit0_loss: 0.1497 - Digit1_loss: 0.1909 - Digit2_loss: 0.0995 - Digit3_loss: 0.0196 - Digit4_loss: 0.0015 - Length_acc: 0.9689 - Digit0_acc: 0.9460 - Digit1_acc: 0.9338 - Digit2_acc: 0.9699 - Digit3_acc: 0.9955 - Digit4_acc: 0.9999 - val_loss: 1.7907 - val_Length_loss: 0.9666 - val_Digit0_loss: 0.3434 - val_Digit1_loss: 0.3785 - val_Digit2_loss: 0.0928 - val_Digit3_loss: 0.0086 - val_Digit4_loss: 8.3633e-04 - val_Length_acc: 0.6830 - val_Digit0_acc: 0.9020 - val_Digit1_acc: 0.9190 - val_Digit2_acc: 0.9828 - val_Digit3_acc: 0.9989 - val_Digit4_acc: 1.0000\n",
      "Epoch 4/25\n",
      "119s - loss: 0.3679 - Length_loss: 0.0576 - Digit0_loss: 0.0953 - Digit1_loss: 0.1186 - Digit2_loss: 0.0776 - Digit3_loss: 0.0178 - Digit4_loss: 0.0010 - Length_acc: 0.9796 - Digit0_acc: 0.9666 - Digit1_acc: 0.9594 - Digit2_acc: 0.9735 - Digit3_acc: 0.9954 - Digit4_acc: 0.9999 - val_loss: 1.2208 - val_Length_loss: 0.5737 - val_Digit0_loss: 0.2452 - val_Digit1_loss: 0.2979 - val_Digit2_loss: 0.0960 - val_Digit3_loss: 0.0077 - val_Digit4_loss: 2.4654e-04 - val_Length_acc: 0.8228 - val_Digit0_acc: 0.9219 - val_Digit1_acc: 0.9292 - val_Digit2_acc: 0.9832 - val_Digit3_acc: 0.9989 - val_Digit4_acc: 1.0000\n",
      "Epoch 5/25\n",
      "119s - loss: 0.2636 - Length_loss: 0.0401 - Digit0_loss: 0.0683 - Digit1_loss: 0.0817 - Digit2_loss: 0.0570 - Digit3_loss: 0.0160 - Digit4_loss: 5.8346e-04 - Length_acc: 0.9855 - Digit0_acc: 0.9766 - Digit1_acc: 0.9719 - Digit2_acc: 0.9800 - Digit3_acc: 0.9955 - Digit4_acc: 1.0000 - val_loss: 0.3420 - val_Length_loss: 0.0885 - val_Digit0_loss: 0.0984 - val_Digit1_loss: 0.1086 - val_Digit2_loss: 0.0410 - val_Digit3_loss: 0.0054 - val_Digit4_loss: 1.5092e-04 - val_Length_acc: 0.9659 - val_Digit0_acc: 0.9649 - val_Digit1_acc: 0.9622 - val_Digit2_acc: 0.9875 - val_Digit3_acc: 0.9989 - val_Digit4_acc: 1.0000\n",
      "Epoch 6/25\n",
      "119s - loss: 0.2008 - Length_loss: 0.0297 - Digit0_loss: 0.0521 - Digit1_loss: 0.0612 - Digit2_loss: 0.0429 - Digit3_loss: 0.0146 - Digit4_loss: 4.0079e-04 - Length_acc: 0.9896 - Digit0_acc: 0.9823 - Digit1_acc: 0.9790 - Digit2_acc: 0.9851 - Digit3_acc: 0.9956 - Digit4_acc: 1.0000 - val_loss: 0.7430 - val_Length_loss: 0.3786 - val_Digit0_loss: 0.1440 - val_Digit1_loss: 0.1719 - val_Digit2_loss: 0.0435 - val_Digit3_loss: 0.0048 - val_Digit4_loss: 1.0359e-04 - val_Length_acc: 0.8996 - val_Digit0_acc: 0.9483 - val_Digit1_acc: 0.9534 - val_Digit2_acc: 0.9880 - val_Digit3_acc: 0.9989 - val_Digit4_acc: 1.0000\n",
      "Epoch 7/25\n",
      "119s - loss: 0.1541 - Length_loss: 0.0211 - Digit0_loss: 0.0408 - Digit1_loss: 0.0458 - Digit2_loss: 0.0327 - Digit3_loss: 0.0134 - Digit4_loss: 3.1364e-04 - Length_acc: 0.9926 - Digit0_acc: 0.9862 - Digit1_acc: 0.9841 - Digit2_acc: 0.9886 - Digit3_acc: 0.9957 - Digit4_acc: 1.0000 - val_loss: 0.3137 - val_Length_loss: 0.0795 - val_Digit0_loss: 0.0959 - val_Digit1_loss: 0.1012 - val_Digit2_loss: 0.0325 - val_Digit3_loss: 0.0045 - val_Digit4_loss: 6.8248e-05 - val_Length_acc: 0.9738 - val_Digit0_acc: 0.9675 - val_Digit1_acc: 0.9671 - val_Digit2_acc: 0.9904 - val_Digit3_acc: 0.9989 - val_Digit4_acc: 1.0000\n",
      "Epoch 8/25\n",
      "119s - loss: 0.1192 - Length_loss: 0.0150 - Digit0_loss: 0.0318 - Digit1_loss: 0.0346 - Digit2_loss: 0.0250 - Digit3_loss: 0.0125 - Digit4_loss: 2.9023e-04 - Length_acc: 0.9948 - Digit0_acc: 0.9892 - Digit1_acc: 0.9881 - Digit2_acc: 0.9911 - Digit3_acc: 0.9957 - Digit4_acc: 1.0000 - val_loss: 0.2743 - val_Length_loss: 0.0759 - val_Digit0_loss: 0.0814 - val_Digit1_loss: 0.0825 - val_Digit2_loss: 0.0289 - val_Digit3_loss: 0.0055 - val_Digit4_loss: 9.4898e-05 - val_Length_acc: 0.9773 - val_Digit0_acc: 0.9726 - val_Digit1_acc: 0.9730 - val_Digit2_acc: 0.9915 - val_Digit3_acc: 0.9989 - val_Digit4_acc: 1.0000\n",
      "Epoch 9/25\n",
      "119s - loss: 0.0945 - Length_loss: 0.0113 - Digit0_loss: 0.0247 - Digit1_loss: 0.0267 - Digit2_loss: 0.0202 - Digit3_loss: 0.0114 - Digit4_loss: 2.6822e-04 - Length_acc: 0.9961 - Digit0_acc: 0.9917 - Digit1_acc: 0.9908 - Digit2_acc: 0.9927 - Digit3_acc: 0.9961 - Digit4_acc: 1.0000 - val_loss: 0.3482 - val_Length_loss: 0.1086 - val_Digit0_loss: 0.1039 - val_Digit1_loss: 0.0971 - val_Digit2_loss: 0.0322 - val_Digit3_loss: 0.0064 - val_Digit4_loss: 4.6785e-05 - val_Length_acc: 0.9706 - val_Digit0_acc: 0.9674 - val_Digit1_acc: 0.9692 - val_Digit2_acc: 0.9907 - val_Digit3_acc: 0.9989 - val_Digit4_acc: 1.0000\n",
      "Epoch 10/25\n",
      "119s - loss: 0.0847 - Length_loss: 0.0114 - Digit0_loss: 0.0219 - Digit1_loss: 0.0238 - Digit2_loss: 0.0168 - Digit3_loss: 0.0106 - Digit4_loss: 2.4110e-04 - Length_acc: 0.9961 - Digit0_acc: 0.9925 - Digit1_acc: 0.9917 - Digit2_acc: 0.9941 - Digit3_acc: 0.9963 - Digit4_acc: 1.0000 - val_loss: 0.4886 - val_Length_loss: 0.1455 - val_Digit0_loss: 0.1595 - val_Digit1_loss: 0.1388 - val_Digit2_loss: 0.0388 - val_Digit3_loss: 0.0059 - val_Digit4_loss: 1.2262e-04 - val_Length_acc: 0.9434 - val_Digit0_acc: 0.9469 - val_Digit1_acc: 0.9562 - val_Digit2_acc: 0.9882 - val_Digit3_acc: 0.9989 - val_Digit4_acc: 1.0000\n",
      "Epoch 11/25\n",
      "119s - loss: 0.0643 - Length_loss: 0.0076 - Digit0_loss: 0.0172 - Digit1_loss: 0.0174 - Digit2_loss: 0.0125 - Digit3_loss: 0.0094 - Digit4_loss: 2.2559e-04 - Length_acc: 0.9974 - Digit0_acc: 0.9942 - Digit1_acc: 0.9941 - Digit2_acc: 0.9956 - Digit3_acc: 0.9967 - Digit4_acc: 1.0000 - val_loss: 0.6694 - val_Length_loss: 0.2286 - val_Digit0_loss: 0.2020 - val_Digit1_loss: 0.1617 - val_Digit2_loss: 0.0623 - val_Digit3_loss: 0.0143 - val_Digit4_loss: 4.0369e-04 - val_Length_acc: 0.9119 - val_Digit0_acc: 0.9343 - val_Digit1_acc: 0.9469 - val_Digit2_acc: 0.9845 - val_Digit3_acc: 0.9985 - val_Digit4_acc: 1.0000\n",
      "Epoch 12/25\n",
      "119s - loss: 0.0519 - Length_loss: 0.0057 - Digit0_loss: 0.0136 - Digit1_loss: 0.0135 - Digit2_loss: 0.0105 - Digit3_loss: 0.0084 - Digit4_loss: 2.1168e-04 - Length_acc: 0.9980 - Digit0_acc: 0.9954 - Digit1_acc: 0.9955 - Digit2_acc: 0.9962 - Digit3_acc: 0.9970 - Digit4_acc: 1.0000 - val_loss: 0.6602 - val_Length_loss: 0.1560 - val_Digit0_loss: 0.2043 - val_Digit1_loss: 0.2068 - val_Digit2_loss: 0.0865 - val_Digit3_loss: 0.0063 - val_Digit4_loss: 1.6685e-04 - val_Length_acc: 0.9404 - val_Digit0_acc: 0.9323 - val_Digit1_acc: 0.9405 - val_Digit2_acc: 0.9725 - val_Digit3_acc: 0.9989 - val_Digit4_acc: 1.0000\n",
      "Epoch 13/25\n",
      "119s - loss: 0.0425 - Length_loss: 0.0052 - Digit0_loss: 0.0115 - Digit1_loss: 0.0106 - Digit2_loss: 0.0080 - Digit3_loss: 0.0070 - Digit4_loss: 1.8193e-04 - Length_acc: 0.9982 - Digit0_acc: 0.9962 - Digit1_acc: 0.9965 - Digit2_acc: 0.9972 - Digit3_acc: 0.9975 - Digit4_acc: 1.0000 - val_loss: 0.3746 - val_Length_loss: 0.1170 - val_Digit0_loss: 0.1097 - val_Digit1_loss: 0.1128 - val_Digit2_loss: 0.0316 - val_Digit3_loss: 0.0035 - val_Digit4_loss: 2.8445e-05 - val_Length_acc: 0.9719 - val_Digit0_acc: 0.9682 - val_Digit1_acc: 0.9690 - val_Digit2_acc: 0.9912 - val_Digit3_acc: 0.9991 - val_Digit4_acc: 1.0000\n",
      "Epoch 14/25\n",
      "119s - loss: 0.0388 - Length_loss: 0.0045 - Digit0_loss: 0.0107 - Digit1_loss: 0.0101 - Digit2_loss: 0.0070 - Digit3_loss: 0.0064 - Digit4_loss: 1.6470e-04 - Length_acc: 0.9985 - Digit0_acc: 0.9964 - Digit1_acc: 0.9965 - Digit2_acc: 0.9976 - Digit3_acc: 0.9977 - Digit4_acc: 1.0000 - val_loss: 0.3305 - val_Length_loss: 0.0935 - val_Digit0_loss: 0.0992 - val_Digit1_loss: 0.1007 - val_Digit2_loss: 0.0331 - val_Digit3_loss: 0.0039 - val_Digit4_loss: 2.8014e-05 - val_Length_acc: 0.9818 - val_Digit0_acc: 0.9720 - val_Digit1_acc: 0.9732 - val_Digit2_acc: 0.9915 - val_Digit3_acc: 0.9991 - val_Digit4_acc: 1.0000\n",
      "Epoch 15/25\n",
      "119s - loss: 0.0323 - Length_loss: 0.0037 - Digit0_loss: 0.0092 - Digit1_loss: 0.0082 - Digit2_loss: 0.0058 - Digit3_loss: 0.0052 - Digit4_loss: 1.4123e-04 - Length_acc: 0.9988 - Digit0_acc: 0.9970 - Digit1_acc: 0.9972 - Digit2_acc: 0.9980 - Digit3_acc: 0.9981 - Digit4_acc: 1.0000 - val_loss: 0.2787 - val_Length_loss: 0.0810 - val_Digit0_loss: 0.0810 - val_Digit1_loss: 0.0851 - val_Digit2_loss: 0.0284 - val_Digit3_loss: 0.0032 - val_Digit4_loss: 2.7913e-05 - val_Length_acc: 0.9811 - val_Digit0_acc: 0.9765 - val_Digit1_acc: 0.9772 - val_Digit2_acc: 0.9923 - val_Digit3_acc: 0.9990 - val_Digit4_acc: 1.0000\n",
      "Epoch 16/25\n",
      "119s - loss: 0.0275 - Length_loss: 0.0032 - Digit0_loss: 0.0072 - Digit1_loss: 0.0069 - Digit2_loss: 0.0052 - Digit3_loss: 0.0049 - Digit4_loss: 1.3376e-04 - Length_acc: 0.9990 - Digit0_acc: 0.9976 - Digit1_acc: 0.9977 - Digit2_acc: 0.9982 - Digit3_acc: 0.9982 - Digit4_acc: 1.0000 - val_loss: 0.3330 - val_Length_loss: 0.1042 - val_Digit0_loss: 0.0876 - val_Digit1_loss: 0.1050 - val_Digit2_loss: 0.0327 - val_Digit3_loss: 0.0036 - val_Digit4_loss: 2.2800e-05 - val_Length_acc: 0.9795 - val_Digit0_acc: 0.9768 - val_Digit1_acc: 0.9745 - val_Digit2_acc: 0.9919 - val_Digit3_acc: 0.9990 - val_Digit4_acc: 1.0000\n",
      "Epoch 17/25\n",
      "119s - loss: 0.0253 - Length_loss: 0.0029 - Digit0_loss: 0.0071 - Digit1_loss: 0.0063 - Digit2_loss: 0.0049 - Digit3_loss: 0.0040 - Digit4_loss: 1.2206e-04 - Length_acc: 0.9990 - Digit0_acc: 0.9977 - Digit1_acc: 0.9979 - Digit2_acc: 0.9983 - Digit3_acc: 0.9985 - Digit4_acc: 1.0000 - val_loss: 0.2913 - val_Length_loss: 0.0892 - val_Digit0_loss: 0.0762 - val_Digit1_loss: 0.0912 - val_Digit2_loss: 0.0313 - val_Digit3_loss: 0.0034 - val_Digit4_loss: 1.2898e-05 - val_Length_acc: 0.9839 - val_Digit0_acc: 0.9806 - val_Digit1_acc: 0.9786 - val_Digit2_acc: 0.9924 - val_Digit3_acc: 0.9991 - val_Digit4_acc: 1.0000\n",
      "Epoch 18/25\n",
      "119s - loss: 0.0279 - Length_loss: 0.0038 - Digit0_loss: 0.0075 - Digit1_loss: 0.0076 - Digit2_loss: 0.0049 - Digit3_loss: 0.0039 - Digit4_loss: 1.2600e-04 - Length_acc: 0.9986 - Digit0_acc: 0.9974 - Digit1_acc: 0.9975 - Digit2_acc: 0.9982 - Digit3_acc: 0.9986 - Digit4_acc: 1.0000 - val_loss: 0.4243 - val_Length_loss: 0.1130 - val_Digit0_loss: 0.1291 - val_Digit1_loss: 0.1363 - val_Digit2_loss: 0.0418 - val_Digit3_loss: 0.0040 - val_Digit4_loss: 5.4761e-05 - val_Length_acc: 0.9725 - val_Digit0_acc: 0.9626 - val_Digit1_acc: 0.9628 - val_Digit2_acc: 0.9900 - val_Digit3_acc: 0.9991 - val_Digit4_acc: 1.0000\n",
      "Epoch 19/25\n",
      "119s - loss: 0.0301 - Length_loss: 0.0045 - Digit0_loss: 0.0077 - Digit1_loss: 0.0081 - Digit2_loss: 0.0058 - Digit3_loss: 0.0037 - Digit4_loss: 1.3600e-04 - Length_acc: 0.9984 - Digit0_acc: 0.9974 - Digit1_acc: 0.9973 - Digit2_acc: 0.9979 - Digit3_acc: 0.9987 - Digit4_acc: 1.0000 - val_loss: 1.0365 - val_Length_loss: 0.5476 - val_Digit0_loss: 0.2138 - val_Digit1_loss: 0.2191 - val_Digit2_loss: 0.0509 - val_Digit3_loss: 0.0050 - val_Digit4_loss: 1.1398e-04 - val_Length_acc: 0.8931 - val_Digit0_acc: 0.9341 - val_Digit1_acc: 0.9508 - val_Digit2_acc: 0.9885 - val_Digit3_acc: 0.9990 - val_Digit4_acc: 1.0000\n",
      "Epoch 20/25\n",
      "119s - loss: 0.0297 - Length_loss: 0.0050 - Digit0_loss: 0.0076 - Digit1_loss: 0.0080 - Digit2_loss: 0.0055 - Digit3_loss: 0.0035 - Digit4_loss: 1.1946e-04 - Length_acc: 0.9985 - Digit0_acc: 0.9974 - Digit1_acc: 0.9973 - Digit2_acc: 0.9981 - Digit3_acc: 0.9987 - Digit4_acc: 1.0000 - val_loss: 0.3718 - val_Length_loss: 0.1037 - val_Digit0_loss: 0.1106 - val_Digit1_loss: 0.1172 - val_Digit2_loss: 0.0366 - val_Digit3_loss: 0.0038 - val_Digit4_loss: 4.0009e-05 - val_Length_acc: 0.9745 - val_Digit0_acc: 0.9683 - val_Digit1_acc: 0.9685 - val_Digit2_acc: 0.9912 - val_Digit3_acc: 0.9992 - val_Digit4_acc: 1.0000\n",
      "Epoch 21/25\n",
      "119s - loss: 0.0241 - Length_loss: 0.0028 - Digit0_loss: 0.0072 - Digit1_loss: 0.0066 - Digit2_loss: 0.0045 - Digit3_loss: 0.0028 - Digit4_loss: 1.2185e-04 - Length_acc: 0.9991 - Digit0_acc: 0.9975 - Digit1_acc: 0.9977 - Digit2_acc: 0.9984 - Digit3_acc: 0.9991 - Digit4_acc: 1.0000 - val_loss: 0.6158 - val_Length_loss: 0.1784 - val_Digit0_loss: 0.2056 - val_Digit1_loss: 0.1811 - val_Digit2_loss: 0.0458 - val_Digit3_loss: 0.0050 - val_Digit4_loss: 4.8448e-05 - val_Length_acc: 0.9578 - val_Digit0_acc: 0.9406 - val_Digit1_acc: 0.9514 - val_Digit2_acc: 0.9889 - val_Digit3_acc: 0.9990 - val_Digit4_acc: 1.0000\n",
      "Epoch 22/25\n",
      "119s - loss: 0.0183 - Length_loss: 0.0023 - Digit0_loss: 0.0052 - Digit1_loss: 0.0047 - Digit2_loss: 0.0034 - Digit3_loss: 0.0025 - Digit4_loss: 1.0478e-04 - Length_acc: 0.9992 - Digit0_acc: 0.9982 - Digit1_acc: 0.9984 - Digit2_acc: 0.9988 - Digit3_acc: 0.9991 - Digit4_acc: 1.0000 - val_loss: 0.3279 - val_Length_loss: 0.0946 - val_Digit0_loss: 0.0900 - val_Digit1_loss: 0.1049 - val_Digit2_loss: 0.0349 - val_Digit3_loss: 0.0035 - val_Digit4_loss: 2.8010e-05 - val_Length_acc: 0.9800 - val_Digit0_acc: 0.9766 - val_Digit1_acc: 0.9749 - val_Digit2_acc: 0.9915 - val_Digit3_acc: 0.9992 - val_Digit4_acc: 1.0000\n",
      "Epoch 23/25\n",
      "119s - loss: 0.0198 - Length_loss: 0.0032 - Digit0_loss: 0.0052 - Digit1_loss: 0.0055 - Digit2_loss: 0.0036 - Digit3_loss: 0.0023 - Digit4_loss: 7.9455e-05 - Length_acc: 0.9990 - Digit0_acc: 0.9982 - Digit1_acc: 0.9981 - Digit2_acc: 0.9987 - Digit3_acc: 0.9992 - Digit4_acc: 1.0000 - val_loss: 0.3488 - val_Length_loss: 0.1101 - val_Digit0_loss: 0.0894 - val_Digit1_loss: 0.1075 - val_Digit2_loss: 0.0376 - val_Digit3_loss: 0.0041 - val_Digit4_loss: 9.0930e-06 - val_Length_acc: 0.9814 - val_Digit0_acc: 0.9788 - val_Digit1_acc: 0.9768 - val_Digit2_acc: 0.9915 - val_Digit3_acc: 0.9991 - val_Digit4_acc: 1.0000\n",
      "Epoch 24/25\n",
      "119s - loss: 0.0173 - Length_loss: 0.0019 - Digit0_loss: 0.0050 - Digit1_loss: 0.0051 - Digit2_loss: 0.0032 - Digit3_loss: 0.0020 - Digit4_loss: 7.8612e-05 - Length_acc: 0.9993 - Digit0_acc: 0.9983 - Digit1_acc: 0.9983 - Digit2_acc: 0.9989 - Digit3_acc: 0.9993 - Digit4_acc: 1.0000 - val_loss: 0.3326 - val_Length_loss: 0.1094 - val_Digit0_loss: 0.0878 - val_Digit1_loss: 0.0971 - val_Digit2_loss: 0.0351 - val_Digit3_loss: 0.0031 - val_Digit4_loss: 1.2823e-05 - val_Length_acc: 0.9796 - val_Digit0_acc: 0.9792 - val_Digit1_acc: 0.9774 - val_Digit2_acc: 0.9919 - val_Digit3_acc: 0.9993 - val_Digit4_acc: 1.0000\n",
      "Epoch 25/25\n",
      "119s - loss: 0.0221 - Length_loss: 0.0040 - Digit0_loss: 0.0061 - Digit1_loss: 0.0060 - Digit2_loss: 0.0038 - Digit3_loss: 0.0021 - Digit4_loss: 9.5420e-05 - Length_acc: 0.9986 - Digit0_acc: 0.9980 - Digit1_acc: 0.9979 - Digit2_acc: 0.9987 - Digit3_acc: 0.9993 - Digit4_acc: 1.0000 - val_loss: 0.4468 - val_Length_loss: 0.1115 - val_Digit0_loss: 0.1407 - val_Digit1_loss: 0.1497 - val_Digit2_loss: 0.0401 - val_Digit3_loss: 0.0048 - val_Digit4_loss: 5.7509e-05 - val_Length_acc: 0.9694 - val_Digit0_acc: 0.9596 - val_Digit1_acc: 0.9594 - val_Digit2_acc: 0.9899 - val_Digit3_acc: 0.9987 - val_Digit4_acc: 1.0000\n",
      "6534/6534 [==============================] - 12s     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Test score: [0.43899389430948965, 0.1047625774417881, 0.13973597806365548, 0.1508404436319688, 0.038974829495037534, 0.0043059681254083576, 0.00037409508017542876, 0.97000306114932977, 0.96063678305485511, 0.95932059478497045, 0.98999093602037147, 0.99895940605638811, 0.99996950997100675]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "modelFile = '/home/carnd/data/svhn/model.h5'\n",
    "\n",
    "import os.path\n",
    "if os.path.isfile(modelFile) is False:\n",
    "    epochs=25\n",
    "\n",
    "    #model = strongLengthBias()\n",
    "    model = getCnnModel()\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='nadam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    trainDigit0  = trainImageDigits[:,0,:]\n",
    "    trainDigit1  = trainImageDigits[:,1,:]\n",
    "    trainDigit2  = trainImageDigits[:,2,:]\n",
    "    trainDigit3  = trainImageDigits[:,3,:]\n",
    "    trainDigit4  = trainImageDigits[:,4,:]\n",
    "\n",
    "    validationDigit0  = validationImageDigits[:,0,:]\n",
    "    validationDigit1  = validationImageDigits[:,1,:]\n",
    "    validationDigit2  = validationImageDigits[:,2,:]\n",
    "    validationDigit3  = validationImageDigits[:,3,:]\n",
    "    validationDigit4  = validationImageDigits[:,4,:]\n",
    "\n",
    "\n",
    "    model.fit(trainImageData, [trainImageLengths, trainDigit0, trainDigit1, trainDigit2, trainDigit3, trainDigit4], verbose=2, nb_epoch=epochs, batch_size=batch_size, validation_data=(validationImageData,[validationImageLengths,validationDigit0,validationDigit1,validationDigit2,validationDigit3,validationDigit4]))\n",
    "    model.save(modelFile)\n",
    "else:\n",
    "    print('Loading saved model')\n",
    "    from keras.models import load_model\n",
    "    model = load_model(modelFile)\n",
    "\n",
    "testDigit0  = testImageDigits[:,0,:]\n",
    "testDigit1  = testImageDigits[:,1,:]\n",
    "testDigit2  = testImageDigits[:,2,:]\n",
    "testDigit3  = testImageDigits[:,3,:]\n",
    "testDigit4  = testImageDigits[:,4,:]\n",
    "\n",
    "score = model.evaluate(testImageData, [testImageLengths, testDigit0, testDigit1, testDigit2, testDigit3, testDigit4], batch_size=32)\n",
    "print('Test score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
